{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image, os, shutil\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "from imagecluster import common as co\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "from imagecluster import imagecluster2 as ic\n",
    "from imagecluster import common as co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set operating system path\n",
    "pj = os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions to build model \n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Keras Model of the VGG16 network, with the output layer set to the\n",
    "    second-to-last fully connected layer 'fc2' of shape (4096,).\"\"\"\n",
    "    # base_model.summary():\n",
    "    #     ....\n",
    "    #     block5_conv4 (Conv2D)        (None, 15, 15, 512)       2359808\n",
    "    #     _________________________________________________________________\n",
    "    #     block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0\n",
    "    #     _________________________________________________________________\n",
    "    #     flatten (Flatten)            (None, 25088)             0\n",
    "    #     _________________________________________________________________\n",
    "    #     fc1 (Dense)                  (None, 4096)              102764544\n",
    "    #     _________________________________________________________________\n",
    "    #     fc2 (Dense)                  (None, 4096)              16781312\n",
    "    #     _________________________________________________________________\n",
    "    #     predictions (Dense)          (None, 1000)              4097000\n",
    "    #\n",
    "    base_model = VGG16(weights='imagenet', include_top=True)\n",
    "    model = Model(inputs=base_model.input,\n",
    "                  outputs=base_model.get_layer('fc2').output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fingerprint(fn, model, size):\n",
    "    try:\n",
    "        \"\"\"Load image from file `fn`, resize to `size` and run through `model`\n",
    "        (keras.models.Model).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : str\n",
    "            filename\n",
    "        model : keras.models.Model instance\n",
    "        size : tuple\n",
    "            input image size (width, height), must match `model`, e.g. (224,224)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fingerprint : 1d array\n",
    "        \"\"\"\n",
    "        print(fn)\n",
    "\n",
    "        # keras.preprocessing.image.load_img() uses img.rezize(shape) with the\n",
    "        # default interpolation of PIL.Image.resize() which is pretty bad (see\n",
    "        # imagecluster/play/pil_resample_methods.py). Given that we are restricted\n",
    "        # to small inputs of 224x224 by the VGG network, we should do our best to\n",
    "        # keep as much information from the original image as possible. This is a\n",
    "        # gut feeling, untested. But given that model.predict() is 10x slower than\n",
    "        # PIL image loading and resizing .. who cares.\n",
    "        #\n",
    "        # (224, 224, 3)\n",
    "        ##img = image.load_img(fn, target_size=size)\n",
    "        img = PIL.Image.open(fn).resize(size, 2)\n",
    "\n",
    "        # (224, 224, {3,1})\n",
    "        arr3d = image.img_to_array(img)\n",
    "\n",
    "        # (224, 224, 1) -> (224, 224, 3)\n",
    "        #\n",
    "        # Simple hack to convert a grayscale image to fake RGB by replication of\n",
    "        # the image data to all 3 channels.\n",
    "        #\n",
    "        # Deep learning models may have learned color-specific filters, but the\n",
    "        # assumption is that structural image features (edges etc) contibute more to\n",
    "        # the image representation than color, such that this hack makes it possible\n",
    "        # to process gray-scale images with nets trained on color images (like\n",
    "        # VGG16).\n",
    "        if arr3d.shape[2] == 1:\n",
    "            arr3d = arr3d.repeat(3, axis=2)\n",
    "\n",
    "        # (1, 224, 224, 3)\n",
    "        arr4d = np.expand_dims(arr3d, axis=0)\n",
    "\n",
    "        # (1, 224, 224, 3)\n",
    "        arr4d_pp = preprocess_input(arr4d)\n",
    "        return model.predict(arr4d_pp)[0,:]\n",
    "    except:\n",
    "        print(fn, \"IMAGE DID NOT FIT ARRAY SHAPE, SKIPPED\")\n",
    "\n",
    "# Cannot use multiprocessing (only tensorflow backend tested):\n",
    "# TypeError: can't pickle _thread.lock objects\n",
    "# The error doesn't come from functools.partial since those objects are\n",
    "# pickable since python3. The reason is the keras.model.Model, which is not\n",
    "# pickable. However keras with tensorflow backend runs multi-threaded\n",
    "# (model.predict()), so we don't need that. I guess it will scale better if we\n",
    "# parallelize over images than to run a muti-threaded tensorflow on each image,\n",
    "# but OK. On low core counts (2-4), it won't matter.\n",
    "#\n",
    "##def _worker(fn, model, size):\n",
    "##    print(fn)\n",
    "##    return fn, fingerprint(fn, model, size)\n",
    "##\n",
    "##def fingerprints(files, model, size=(224,224)):\n",
    "##    worker = functools.partial(_worker,\n",
    "##                               model=model,\n",
    "##                               size=size)\n",
    "##    pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "##    return dict(pool.map(worker, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fingerprints(files, model, size=(224,224)):\n",
    "    \"\"\"Calculate fingerprints for all `files`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files : sequence\n",
    "        image filenames\n",
    "    model, size : see :func:`fingerprint`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fingerprints : dict\n",
    "        {filename1: array([...]),\n",
    "         filename2: array([...]),\n",
    "         ...\n",
    "         }\n",
    "    \"\"\"\n",
    "    output = dict((fn, fingerprint(fn, model, size)) for fn in files)\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster(fps, sim=0.5, method='average', metric='euclidean'):\n",
    "    try:\n",
    "        \"\"\"Hierarchical clustering of images based on image fingerprints.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fps: dict\n",
    "            output of :func:`fingerprints`\n",
    "        sim : float 0..1\n",
    "            similarity index\n",
    "        method : see scipy.hierarchy.linkage(), all except 'centroid' produce\n",
    "            pretty much the same result\n",
    "        metric : see scipy.hierarchy.linkage(), make sure to use 'euclidean' in\n",
    "            case of method='centroid', 'median' or 'ward'\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        clusters : nested list\n",
    "            [[filename1, filename5],                    # cluster 1\n",
    "             [filename23],                              # cluster 2\n",
    "             [filename48, filename2, filename42, ...],  # cluster 3\n",
    "             ...\n",
    "             ]\n",
    "        \"\"\"\n",
    "        assert 0 <= sim <= 1, \"sim not 0..1\"\n",
    "        # array(list(...)): 2d array\n",
    "        #   [[... fingerprint of image1 (4096,) ...],\n",
    "        #    [... fingerprint of image2 (4096,) ...],\n",
    "        #    ...\n",
    "        #    ]\n",
    "        try:\n",
    "            dfps = distance.pdist(np.array(list(fps.values())), metric)\n",
    "            files = list(fps.keys())\n",
    "        except:\n",
    "            print(\"C1\")\n",
    "        # hierarchical/agglomerative clustering (Z = linkage matrix, construct\n",
    "        # dendrogram)\n",
    "        \n",
    "        Z = hierarchy.linkage(dfps, method=method, metric=metric)\n",
    "        # cut dendrogram, extract clusters\n",
    "        cut = hierarchy.fcluster(Z, t=dfps.max()*(1.0-sim), criterion='distance')\n",
    "        cluster_dct = dict((ii,[]) for ii in np.unique(cut))\n",
    "        for iimg,iclus in enumerate(cut):\n",
    "            cluster_dct[iclus].append(files[iimg])\n",
    "        return list(cluster_dct.values())\n",
    "    except:\n",
    "        print(\"CLUSTER ISSUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_links(clusters, cluster_dr):\n",
    "    # group all clusters (cluster = list_of_files) of equal size together\n",
    "    # {number_of_files1: [[list_of_files], [list_of_files],...],\n",
    "    #  number_of_files2: [[list_of_files],...],\n",
    "    # }\n",
    "    cdct_multi = {}\n",
    "    for x in clusters:\n",
    "        nn = len(x)\n",
    "        if nn > 1:\n",
    "            if not (nn in cdct_multi.keys()):\n",
    "                cdct_multi[nn] = [x]\n",
    "            else:\n",
    "                cdct_multi[nn].append(x)\n",
    "\n",
    "    #print(\"cluster dir: {}\".format(cluster_dr))\n",
    "    #print(\"items per cluster : number of such clusters\")\n",
    "    if os.path.exists(cluster_dr):\n",
    "        shutil.rmtree(cluster_dr)\n",
    "    \n",
    "    dfout = pd.DataFrame({'cluster_n':[],'image':[]})\n",
    "    for cluster_n, nn in enumerate(np.sort(list(cdct_multi.keys()))):\n",
    "        cluster_list = cdct_multi[nn]\n",
    "        #print(\"{} : {}\".format(nn, len(cluster_list)))\n",
    "        for insidegroup, lst in enumerate(cluster_list): # each cluster \n",
    "            dr = pj(cluster_dr,\n",
    "                    'cluster_with_{}'.format(nn),\n",
    "                    'cluster_{}'.format(insidegroup))\n",
    "            for record, fn in enumerate(lst):  # each record \n",
    "                link = pj(dr, os.path.basename(fn))\n",
    "                os.makedirs(os.path.dirname(link), exist_ok=True)\n",
    "                dftemp = pd.DataFrame({'cluster_n':[cluster_n],'image':[fn]})\n",
    "                dfout = dfout.append(dftemp)\n",
    "                #os.symlink(os.path.abspath(fn), link)\n",
    "    return dfout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading fingerprints database training_images/imagecluster\\fingerprints.pk ...\n",
      "clustering ...\n"
     ]
    }
   ],
   "source": [
    "# Set training images directory, similarty score, and run the model...\n",
    "\n",
    "pj = os.path.join\n",
    "ic_base_dir = 'imagecluster'\n",
    "imagedir = \"training_images/\"\n",
    "sim = 0.49\n",
    "\n",
    "dbfn = pj(imagedir, ic_base_dir, 'fingerprints.pk')\n",
    "if not os.path.exists(dbfn):\n",
    "    os.makedirs(os.path.dirname(dbfn), exist_ok=True)\n",
    "    print(\"no fingerprints database {} found\".format(dbfn))\n",
    "    files = co.get_files(imagedir)\n",
    "    model = get_model()\n",
    "    print(\"running all images through NN model ...\".format(dbfn))\n",
    "    fps = fingerprints(files, model, size=(224,224))\n",
    "    co.write_pk(fps, dbfn)\n",
    "    print(\"loading fingerprints database {} ...\".format(dbfn))\n",
    "    fps = co.read_pk(dbfn)\n",
    "    fps2 = {}\n",
    "    for x in fps:\n",
    "        key = x\n",
    "        value = fps[key]\n",
    "        try:\n",
    "            value.shape\n",
    "            fps2[key] = value\n",
    "        except:\n",
    "            pass\n",
    "else:\n",
    "    print(\"loading fingerprints database {} ...\".format(dbfn))\n",
    "    fps = co.read_pk(dbfn)\n",
    "    fps2 = {}\n",
    "    for x in fps:\n",
    "        key = x\n",
    "        value = fps[key]\n",
    "        try:\n",
    "            value.shape\n",
    "            fps2[key] = value\n",
    "        except:\n",
    "            pass\n",
    "print(\"clustering ...\")\n",
    "\n",
    "df = make_links(cluster(fps2, sim), pj(imagedir, ic_base_dir, 'clusters'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model (assuming labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_n</th>\n",
       "      <th>image</th>\n",
       "      <th>real_label</th>\n",
       "      <th>predicted_label_by_cluster_majority</th>\n",
       "      <th>prediction_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>training_images/taj23.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>training_images/taj76.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>training_images/taj26.jpeg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>training_images/taj46.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>training_images/taj72.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_n                       image  real_label  \\\n",
       "0        0.0   training_images/taj23.jpg       False   \n",
       "1        0.0   training_images/taj76.jpg       False   \n",
       "2        0.0  training_images/taj26.jpeg       False   \n",
       "3        0.0   training_images/taj46.jpg       False   \n",
       "4        1.0   training_images/taj72.jpg       False   \n",
       "\n",
       "   predicted_label_by_cluster_majority  prediction_correct  \n",
       "0                                False                   1  \n",
       "1                                False                   1  \n",
       "2                                False                   1  \n",
       "3                                False                   1  \n",
       "4                                False                   1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing as we know what cluster the images 'should' have fallen in (i.e. we have labelled data in this case) \n",
    "# we can also score the model using more traditional \n",
    "\n",
    "# BEN = 1\n",
    "# TAJ = 0\n",
    "\n",
    "# find those which were labelled in cluster 1\n",
    "df['real_label'] = df['image'].str.contains('ben')\n",
    "# find the majority predictions for that cluster \n",
    "df_cluster_majority = df.groupby(['cluster_n']).agg(lambda x:x.value_counts().index[0]).reset_index()[['cluster_n','real_label']]\n",
    "df_cluster_majority = df_cluster_majority.rename(columns={'real_label':'predicted_label_by_cluster_majority'})\n",
    "# merge it back with the df \n",
    "df_final = df.merge(df_cluster_majority,on=\"cluster_n\",how='left')\n",
    "# create a predicted column based on the majority prediction\n",
    "df_final['prediction_correct'] = np.where((df_final['real_label'] == df_final['predicted_label_by_cluster_majority']), 1, 0)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.96875\n"
     ]
    }
   ],
   "source": [
    "acc = df_final['prediction_correct'].sum() / len(df_final)\n",
    "print(\"model accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjusted rand score :  0.8779494452775937\n",
      "adjusted mutual info score :  0.8028290167538461\n",
      "homogeneity score :  0.8056594758347162\n",
      "v measure score :  0.8048059686766992\n"
     ]
    }
   ],
   "source": [
    "# Clustering metric (again only assuming we had labelled data)\n",
    "\n",
    "from sklearn import metrics\n",
    "labels_true = list(df_final['real_label'])\n",
    "labels_pred = list(df_final['predicted_label_by_cluster_majority'])\n",
    "\n",
    "print(\"adjusted rand score : \", metrics.adjusted_rand_score(labels_true, labels_pred))\n",
    "print(\"adjusted mutual info score : \", metrics.adjusted_mutual_info_score(labels_true, labels_pred)  )\n",
    "print(\"homogeneity score : \", metrics.homogeneity_score(labels_true, labels_pred)  )\n",
    "print(\"v measure score : \", metrics.v_measure_score(labels_true, labels_pred)    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
