{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mysymlink(source, link_name):\n",
    "    import os\n",
    "    os_symlink = getattr(os, \"symlink\", None)\n",
    "    if callable(os_symlink):\n",
    "        os_symlink(source, link_name)\n",
    "    else:\n",
    "        import ctypes\n",
    "        csl = ctypes.windll.kernel32.CreateSymbolicLinkW\n",
    "        csl.argtypes = (ctypes.c_wchar_p, ctypes.c_wchar_p, ctypes.c_uint32)\n",
    "        csl.restype = ctypes.c_ubyte\n",
    "        flags = 1 if os.path.isdir(source) else 0\n",
    "        if csl(link_name, source, flags) == 0:\n",
    "            raise ctypes.WinError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "index = pd.read_csv('index.csv') # index [ID, URL]\n",
    "test = pd.read_csv('test.csv') # test [ID, URL]\n",
    "sample_submission = pd.read_csv('sample_submission.csv') # sample_submission [ID, similar_image_ID_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098461\n",
      "117703\n",
      "117703\n"
     ]
    }
   ],
   "source": [
    "print(len(index))\n",
    "print(len(sample_submission))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define image download function\n",
    "def download_images(df = None, folder = None, file_extension = None):\n",
    "    import os\n",
    "    import urllib.request\n",
    "    image_dict = df.set_index('id').T.to_dict('list')\n",
    "    for image in image_dict.keys():\n",
    "        image_id = image\n",
    "        if os.path.isfile(image_id) == False:\n",
    "            url = image_dict[image][0]\n",
    "            image_file_path = folder + image_id + file_extension\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, image_file_path)\n",
    "            except:\n",
    "                print(\"url error:\", url)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url error: https://lh3.googleusercontent.com/-XQst1PsHe24/V__uG4aI6sI/AAAAAAABBBI/87ANLKG1Q5UweP8vSbq9WxJHnybRrNuSwCOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-n2TDQ48sta8/WL4veiOm2HI/AAAAAAAAE_0/8DzBIpQRJIAb588vw2LMttsLDFkfHFKkwCOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-JM3w7egHnw4/WJUM6Lya-wI/AAAAAAAAAc4/J20l2xHoJfUFol9d6thOMzZGugQw6MvgwCOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-9Pi_T0X1OVs/WLK5Ju3RaNI/AAAAAAAAIUw/iLfk9stSEXsa07-Sc864InECxvK2WTAwwCOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/--AmkDnU2-3k/WO2US7rcvqI/AAAAAAAAIN0/7RH-1sYtKwMcDmEzHRIH7LdoNLgGCNg3QCOcB/s1600/\n",
      "url error: http://lh3.ggpht.com/-vQabOfI3eNA/ShrkmkKqQFI/AAAAAAAAA7g/V_SHsTG0ht8/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-0KeK-3foADw/WOthdEUm-AI/AAAAAAAAAEE/ngE47mKlDrYRt6ek828H6LTZbyNLosGywCOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-94wCs-rwLVA/WMnDtQihGYI/AAAAAAAAGAY/Wg-cE9tRiHojQMAEGbdOhgLh38bRk63EgCOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-h6UFDk499x8/WNKFjn-_YiI/AAAAAAAAYrU/QQXb0wuEasIATfvWg7DjujGsRASGQHCKACOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-PkO3p4zoxx4/WIGoNpiQysI/AAAAAAAAKFI/wOSp52VwfQkwzbKEY3pPddywyOX1Gpi4ACOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-MQJB1UzcMQE/WN4NMyLEqCI/AAAAAAAAA2I/ZDxlRIe55Zk5auJsiZGEPhdJnzKePbj3ACOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-nj2zVZkUmC4/WJwvF23lPzI/AAAAAAAAAC0/whw-kyDyproZI9vBHZCL3HQRBlTtp3FtQCOcB/s1600/\n",
      "url error: https://lh3.googleusercontent.com/-1TOcRpEW_Yw/V_bHZMWhjwI/AAAAAAAAI18/QuGxcaxESTcemn7hAeeHrNsZIhJ9yvtzgCOcB/s1600/\n"
     ]
    }
   ],
   "source": [
    "# Download sample of test data \n",
    "test_df = test.iloc[0:1000]\n",
    "download_images(df = test_df, folder = \"image_downloads_test/\", file_extension = \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download sample of index data \n",
    "index_df = index.iloc[0:1000]\n",
    "download_images(df = index_df, folder = \"image_downloads_index/\", file_extension = \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image, os, shutil\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "from imagecluster import common as co\n",
    "\n",
    "pj = os.path.join\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Keras Model of the VGG16 network, with the output layer set to the\n",
    "    second-to-last fully connected layer 'fc2' of shape (4096,).\"\"\"\n",
    "    # base_model.summary():\n",
    "    #     ....\n",
    "    #     block5_conv4 (Conv2D)        (None, 15, 15, 512)       2359808\n",
    "    #     _________________________________________________________________\n",
    "    #     block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0\n",
    "    #     _________________________________________________________________\n",
    "    #     flatten (Flatten)            (None, 25088)             0\n",
    "    #     _________________________________________________________________\n",
    "    #     fc1 (Dense)                  (None, 4096)              102764544\n",
    "    #     _________________________________________________________________\n",
    "    #     fc2 (Dense)                  (None, 4096)              16781312\n",
    "    #     _________________________________________________________________\n",
    "    #     predictions (Dense)          (None, 1000)              4097000\n",
    "    #\n",
    "    base_model = VGG16(weights='imagenet', include_top=True)\n",
    "    model = Model(inputs=base_model.input,\n",
    "                  outputs=base_model.get_layer('fc2').output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def fingerprint(fn, model, size):\n",
    "    try:\n",
    "        \"\"\"Load image from file `fn`, resize to `size` and run through `model`\n",
    "        (keras.models.Model).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : str\n",
    "            filename\n",
    "        model : keras.models.Model instance\n",
    "        size : tuple\n",
    "            input image size (width, height), must match `model`, e.g. (224,224)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fingerprint : 1d array\n",
    "        \"\"\"\n",
    "        print(fn)\n",
    "\n",
    "        # keras.preprocessing.image.load_img() uses img.rezize(shape) with the\n",
    "        # default interpolation of PIL.Image.resize() which is pretty bad (see\n",
    "        # imagecluster/play/pil_resample_methods.py). Given that we are restricted\n",
    "        # to small inputs of 224x224 by the VGG network, we should do our best to\n",
    "        # keep as much information from the original image as possible. This is a\n",
    "        # gut feeling, untested. But given that model.predict() is 10x slower than\n",
    "        # PIL image loading and resizing .. who cares.\n",
    "        #\n",
    "        # (224, 224, 3)\n",
    "        ##img = image.load_img(fn, target_size=size)\n",
    "        img = PIL.Image.open(fn).resize(size, 2)\n",
    "\n",
    "        # (224, 224, {3,1})\n",
    "        arr3d = image.img_to_array(img)\n",
    "\n",
    "        # (224, 224, 1) -> (224, 224, 3)\n",
    "        #\n",
    "        # Simple hack to convert a grayscale image to fake RGB by replication of\n",
    "        # the image data to all 3 channels.\n",
    "        #\n",
    "        # Deep learning models may have learned color-specific filters, but the\n",
    "        # assumption is that structural image features (edges etc) contibute more to\n",
    "        # the image representation than color, such that this hack makes it possible\n",
    "        # to process gray-scale images with nets trained on color images (like\n",
    "        # VGG16).\n",
    "        if arr3d.shape[2] == 1:\n",
    "            arr3d = arr3d.repeat(3, axis=2)\n",
    "\n",
    "        # (1, 224, 224, 3)\n",
    "        arr4d = np.expand_dims(arr3d, axis=0)\n",
    "\n",
    "        # (1, 224, 224, 3)\n",
    "        arr4d_pp = preprocess_input(arr4d)\n",
    "        return model.predict(arr4d_pp)[0,:]\n",
    "    except:\n",
    "        print(fn, \"IMAGE DID NOT FIT ARRAY SHAPE, SKIPPED\")\n",
    "\n",
    "# Cannot use multiprocessing (only tensorflow backend tested):\n",
    "# TypeError: can't pickle _thread.lock objects\n",
    "# The error doesn't come from functools.partial since those objects are\n",
    "# pickable since python3. The reason is the keras.model.Model, which is not\n",
    "# pickable. However keras with tensorflow backend runs multi-threaded\n",
    "# (model.predict()), so we don't need that. I guess it will scale better if we\n",
    "# parallelize over images than to run a muti-threaded tensorflow on each image,\n",
    "# but OK. On low core counts (2-4), it won't matter.\n",
    "#\n",
    "##def _worker(fn, model, size):\n",
    "##    print(fn)\n",
    "##    return fn, fingerprint(fn, model, size)\n",
    "##\n",
    "##def fingerprints(files, model, size=(224,224)):\n",
    "##    worker = functools.partial(_worker,\n",
    "##                               model=model,\n",
    "##                               size=size)\n",
    "##    pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "##    return dict(pool.map(worker, files))\n",
    "\n",
    "\n",
    "def fingerprints(files, model, size=(224,224)):\n",
    "    \"\"\"Calculate fingerprints for all `files`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files : sequence\n",
    "        image filenames\n",
    "    model, size : see :func:`fingerprint`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fingerprints : dict\n",
    "        {filename1: array([...]),\n",
    "         filename2: array([...]),\n",
    "         ...\n",
    "         }\n",
    "    \"\"\"\n",
    "    output = dict((fn, fingerprint(fn, model, size)) for fn in files)\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def cluster(fps, sim=0.5, method='average', metric='euclidean'):\n",
    "    try:\n",
    "        \"\"\"Hierarchical clustering of images based on image fingerprints.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fps: dict\n",
    "            output of :func:`fingerprints`\n",
    "        sim : float 0..1\n",
    "            similarity index\n",
    "        method : see scipy.hierarchy.linkage(), all except 'centroid' produce\n",
    "            pretty much the same result\n",
    "        metric : see scipy.hierarchy.linkage(), make sure to use 'euclidean' in\n",
    "            case of method='centroid', 'median' or 'ward'\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        clusters : nested list\n",
    "            [[filename1, filename5],                    # cluster 1\n",
    "             [filename23],                              # cluster 2\n",
    "             [filename48, filename2, filename42, ...],  # cluster 3\n",
    "             ...\n",
    "             ]\n",
    "        \"\"\"\n",
    "        assert 0 <= sim <= 1, \"sim not 0..1\"\n",
    "        # array(list(...)): 2d array\n",
    "        #   [[... fingerprint of image1 (4096,) ...],\n",
    "        #    [... fingerprint of image2 (4096,) ...],\n",
    "        #    ...\n",
    "        #    ]\n",
    "        try:\n",
    "            dfps = distance.pdist(np.array(list(fps.values())), metric)\n",
    "            files = list(fps.keys())\n",
    "        except:\n",
    "            print(\"C1\")\n",
    "        # hierarchical/agglomerative clustering (Z = linkage matrix, construct\n",
    "        # dendrogram)\n",
    "        \n",
    "        Z = hierarchy.linkage(dfps, method=method, metric=metric)\n",
    "        # cut dendrogram, extract clusters\n",
    "        cut = hierarchy.fcluster(Z, t=dfps.max()*(1.0-sim), criterion='distance')\n",
    "        cluster_dct = dict((ii,[]) for ii in np.unique(cut))\n",
    "        for iimg,iclus in enumerate(cut):\n",
    "            cluster_dct[iclus].append(files[iimg])\n",
    "        return list(cluster_dct.values())\n",
    "    except:\n",
    "        print(\"CLUSTER ISSUE\")\n",
    "\n",
    "\n",
    "def make_links(clusters, cluster_dr):\n",
    "    # group all clusters (cluster = list_of_files) of equal size together\n",
    "    # {number_of_files1: [[list_of_files], [list_of_files],...],\n",
    "    #  number_of_files2: [[list_of_files],...],\n",
    "    # }\n",
    "    cdct_multi = {}\n",
    "    for x in clusters:\n",
    "        nn = len(x)\n",
    "        if nn > 1:\n",
    "            if not (nn in cdct_multi.keys()):\n",
    "                cdct_multi[nn] = [x]\n",
    "            else:\n",
    "                cdct_multi[nn].append(x)\n",
    "\n",
    "    #print(\"cluster dir: {}\".format(cluster_dr))\n",
    "    #print(\"items per cluster : number of such clusters\")\n",
    "    if os.path.exists(cluster_dr):\n",
    "        shutil.rmtree(cluster_dr)\n",
    "    \n",
    "    dfout = pd.DataFrame({'cluster_n':[],'image':[]})\n",
    "    for cluster_n, nn in enumerate(np.sort(list(cdct_multi.keys()))):\n",
    "        cluster_list = cdct_multi[nn]\n",
    "        #print(\"{} : {}\".format(nn, len(cluster_list)))\n",
    "        for insidegroup, lst in enumerate(cluster_list): # each cluster \n",
    "            dr = pj(cluster_dr,\n",
    "                    'cluster_with_{}'.format(nn),\n",
    "                    'cluster_{}'.format(insidegroup))\n",
    "            for record, fn in enumerate(lst):  # each record \n",
    "                link = pj(dr, os.path.basename(fn))\n",
    "                os.makedirs(os.path.dirname(link), exist_ok=True)\n",
    "                dftemp = pd.DataFrame({'cluster_n':[cluster_n],'image':[fn]})\n",
    "                dfout = dfout.append(dftemp)\n",
    "                #os.symlink(os.path.abspath(fn), link)\n",
    "    return dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading fingerprints database test_image_two_groups/imagecluster\\fingerprints.pk ...\n",
      "clustering ...\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "from imagecluster import imagecluster2 as ic\n",
    "from imagecluster import common as co\n",
    "\n",
    "pj = os.path.join\n",
    "ic_base_dir = 'imagecluster'\n",
    "imagedir = \"test_image_two_groups/\"\n",
    "sim = 0.49\n",
    "\n",
    "dbfn = pj(imagedir, ic_base_dir, 'fingerprints.pk')\n",
    "if not os.path.exists(dbfn):\n",
    "    os.makedirs(os.path.dirname(dbfn), exist_ok=True)\n",
    "    print(\"no fingerprints database {} found\".format(dbfn))\n",
    "    files = co.get_files(imagedir)\n",
    "    model = get_model()\n",
    "    print(\"running all images through NN model ...\".format(dbfn))\n",
    "    fps = fingerprints(files, model, size=(224,224))\n",
    "    co.write_pk(fps, dbfn)\n",
    "else:\n",
    "    print(\"loading fingerprints database {} ...\".format(dbfn))\n",
    "    fps = co.read_pk(dbfn)\n",
    "    fps2 = {}\n",
    "    for x in fps:\n",
    "        key = x\n",
    "        value = fps[key]\n",
    "        try:\n",
    "            value.shape\n",
    "            fps2[key] = value\n",
    "        except:\n",
    "            pass\n",
    "print(\"clustering ...\")\n",
    "df = make_links(cluster(fps2, sim), pj(imagedir, ic_base_dir, 'clusters'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ben_real'] = df['image'].str.contains('ben')\n",
    "df_cluster_majority = df.groupby(['cluster_n']).agg(lambda x:x.value_counts().index[0]).reset_index()[['cluster_n','ben_real']]\n",
    "df_cluster_majority = df_cluster_majority.rename(columns={'ben_real':'cluster_majority'})\n",
    "df_final = df.merge(df_cluster_majority,on=\"cluster_n\",how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_n</th>\n",
       "      <th>image</th>\n",
       "      <th>ben_real</th>\n",
       "      <th>cluster_majority</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test_image_two_groups/taj23.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test_image_two_groups/taj76.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test_image_two_groups/taj26.jpeg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test_image_two_groups/taj46.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>test_image_two_groups/taj75.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_n                             image  ben_real  cluster_majority  \\\n",
       "0        0.0   test_image_two_groups/taj23.jpg     False             False   \n",
       "1        0.0   test_image_two_groups/taj76.jpg     False             False   \n",
       "2        0.0  test_image_two_groups/taj26.jpeg     False             False   \n",
       "3        0.0   test_image_two_groups/taj46.jpg     False             False   \n",
       "4        1.0   test_image_two_groups/taj75.jpg     False             False   \n",
       "\n",
       "   result  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['result'] = np.where((df_final['ben_real'] == df_final['cluster_majority']), 1, 0)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96875"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['result'].sum() / len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
